# Gesture-Flow
Project Overview

GestureFlow is an accessibility-focused project aimed at enabling individuals with physical disabilities to interact with computers through hand gestures and eye movements. The system is designed to improve accessibility and enhance human-computer interaction, integrating advanced machine learning techniques for gesture and voice recognition.

# Features

Hand gesture recognition for cursor navigation and control.

Eye movement tracking for selection and interaction.

Voice command recognition for hands-free operation.

High accuracy (95%) in gesture recognition.

Accessibility improvement of 30% for physically disabled users.

# Technologies Used

Programming Languages: Python

# Libraries:

Pandas, Numpy: Data manipulation

Scikit-Learn: Model building

SpeechRecognition: Voice command recognition

OpenCV: Computer vision and image processing

TensorFlow, PyTorch: Deep learning frameworks

# Hardware Requirements:

Standard Webcam for gesture tracking

Microphone for voice recognition

System Architecture

# Input Layer:

Webcam captures real-time video for hand gesture detection.

Microphone records voice commands for speech recognition.

# Processing Layer:

Preprocessing of video frames to detect hand landmarks using OpenCV.

Feature extraction and training using TensorFlow and PyTorch.

# Output Layer:

Translates gestures and voice commands into computer actions.

# Contact

For further information or support, please contact:

Name: Riya Khilari

Email: riyakhilari@gmail.com

